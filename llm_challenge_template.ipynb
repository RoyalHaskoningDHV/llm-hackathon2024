{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sbuergers/llm-hackathon/blob/add_gpt4_api/llm_challenge_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl4Qy5eOhH4_"
   },
   "source": [
    "# Welcome to the Large Language Models Challenge!\n",
    "\n",
    "This is a template notebook. __Copy it__ and start hacking away if you like. We suggest removing the `_template` suffix and replacing it with your team name. If you do not have a team name yet, have a look below. There are already a few useful snippets of code that might help you in your quest, including a random team name generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEfibUJykXI8",
    "outputId": "5ddd8f41-aa98-46e8-c00c-fcdcc8ddb82c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated team name:  noble_monkeys\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Function to generate a random team name\n",
    "def generate_team_name():\n",
    "    adjectives = [\"Agile\", \"Brave\", \"Clever\", \"Daring\", \"Energetic\", \"Fearless\", \"Gallant\", \"Heroic\", \"Innovative\", \"Jovial\", \"Keen\", \"Loyal\", \"Mighty\", \"Noble\", \"Optimistic\", \"Persistent\", \"Quick\", \"Resilient\", \"Strong\", \"Tenacious\", \"Unyielding\", \"Valiant\", \"Wise\", \"Xenial\", \"Youthful\", \"Zealous\"]\n",
    "    nouns = [\"Antelopes\", \"Bears\", \"Cheetahs\", \"Dolphins\", \"Elephants\", \"Foxes\", \"Giraffes\", \"Hawks\", \"Iguanas\", \"Jaguars\", \"Kangaroos\", \"Lions\", \"Monkeys\", \"Nightingales\", \"Owls\", \"Penguins\", \"Quails\", \"Rabbits\", \"Snakes\", \"Tigers\", \"Unicorns\", \"Vultures\", \"Wolves\", \"Xiphosuran\", \"Yaks\", \"Zebras\"]\n",
    "    adjective = random.choice(adjectives)\n",
    "    noun = random.choice(nouns)\n",
    "    return adjective.lower() + \"_\" + noun.lower()\n",
    "\n",
    "# Generate a random team name\n",
    "team_name = generate_team_name()\n",
    "print(\"Generated team name: \", team_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcGOCbSaqAk2"
   },
   "source": [
    "##Getting results from the classical machine learning model\n",
    "\n",
    "There are 5 models, one for each level of the hierarchy. You can select which one to query using the `level` parameter in the `get_model_output` function. Also have a look at the other parameters you can pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZB1IZ6QlFsh",
    "outputId": "8b7c9bb9-b364-49de-9cf3-11b7a6c61c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CPV-code': {'631': '45233120-6', '646': '79000000-4', '474': '71242000-6', '130': '45233100-0', '527': '90919300-5'}, 'Omschrijving': {'631': 'Wegenbouwwerken', '646': 'Zakelijke dienstverlening: juridisch, marketing, consulting, drukkerij en beveiliging', '474': 'Project- en ontwerpvoorbereiding, kostenraming', '130': 'Bouwwerkzaamheden voor hoofdwegen en wegen', '527': 'Schoonmaken van scholen'}, 'Score': {'631': 0.002438464944395204, '646': 0.0021191854887598893, '474': 0.0018482626442439531, '130': 0.001817809503174387, '527': 0.0017991071263125358}, 'Type opdracht': {'631': 'werken', '646': 'diensten', '474': 'diensten', '130': 'werken', '527': 'diensten'}, 'important_words': {'631': 'bruggenbouw, officieel, project, spannend, in_dienen', '646': 'spannend, overeen_komen, project, bruggenbouw, bedrijf', '474': 'spannend, voorstel, inschrijving, project, nodig', '130': 'bruggenbouw, overeen_komen, brug, voorstel, nieuw', '527': 'officieel, ervaren, spannend, voorstel, in_dienen'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "FUN_URL = \"https://cpvclassifier.azurewebsites.net/api/azfun_predict_cpv_light\"\n",
    "\n",
    "\n",
    "def get_model_output(tender_text: str, level: str, num_pred: int, service_filter: str) -> dict:\n",
    "    \"\"\"Get model output from API endpoint (see cpv repository for details).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tender_text: str\n",
    "        The text for which to make predictions\n",
    "    level: str\n",
    "        The level at which to run the model (e.g. department or group).\n",
    "    num_pred : int\n",
    "        How many predictions to show (top `num_pred` predictions are shown)\n",
    "    service_filter : str\n",
    "        Users can select only `diensten` (services), `werken` (works),\n",
    "        `leveringen` (deliveries), or `diensten, leveringen, werken` (all).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with the model output, can be coerced into a dataframe.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"tender_text\": tender_text,\n",
    "        \"level\": level,\n",
    "        \"num_predictions\": num_pred,\n",
    "        \"service_filter\": service_filter,\n",
    "    }\n",
    "    response = requests.post(FUN_URL, params=payload)\n",
    "    output_dict = response.json()\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "tender_text = \"Dit document is een officiële uitnodiging tot inschrijving voor de bouw van een nieuwe brug. De CPV-code voor deze aanbesteding is 45221100, wat overeenkomt met bruggenbouw en -herstel. Wij nodigen gekwalificeerde en ervaren bedrijven uit om hun voorstellen in te dienen voor dit spannende project.\"\n",
    "level = \"Omschrijving\"  # From highest to lowest: 'afdeling', 'groep', 'categorie', 'klasse', 'Omschrijving'\"\n",
    "results_dict = get_model_output(\n",
    "    tender_text=tender_text,\n",
    "    level=level,\n",
    "    num_pred=5,\n",
    "    service_filter=None,\n",
    ")\n",
    "print(results_dict.get(\"results\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Liknda-Hqffm"
   },
   "source": [
    "## Why not scrape some additional info from the web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKHwEUtGgtNt"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Function to extract first text paragraph after first h2 tag from website.\n",
    "# (If you use https://cpvcodes.eu/en/{cpv_code}-cpv/, you get a detailed description for that code)\n",
    "def extract_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the first <h2> tag\n",
    "    first_h2 = soup.find('h2')\n",
    "\n",
    "    if first_h2:\n",
    "        # Find the next <p> tag after the first <h2> tag\n",
    "        first_p_after_h2 = first_h2.find_next('p')\n",
    "        if first_p_after_h2:\n",
    "            return first_p_after_h2.text\n",
    "        else:\n",
    "            return \"No <p> tag found after the first <h2> tag.\"\n",
    "    else:\n",
    "        return \"No <h2> tag found in the webpage.\"\n",
    "\n",
    "\n",
    "# Test the function\n",
    "url = \"https://cpvcodes.eu/en/03211000-cpv/\"\n",
    "print(extract_text(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq7voKtcg_yn",
    "outputId": "027f32b7-6597-4b37-827c-94be5fb41deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cereals category includes various types of grains that are commonly used as food sources. These grains are essential ingredients in many food products and are widely consumed worldwide. The subcategories within this category consist of Wheat, Maize (corn), Rice, Barley, Rye, Oats, Malt, and Grain products. Wheat is a versatile grain used in bread, pasta, and pastries. Maize is primarily used for animal feed and as a raw material for various food products. Rice is a staple food in many cultures and is consumed in various forms. Barley is often used in brewing and as a nutritious grain. Rye and oats are commonly used in bread, cereals, and other baked goods. Malt is a key ingredient in beer production. Grain products encompass a wide range of processed goods derived from grains, such as flour, cereals, and snacks.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25B_EQh_hBZe",
    "outputId": "c897b3f8-303b-4903-95c4-7b719e614766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHCDlIEDs-tC"
   },
   "source": [
    "## We use a GPT-4o mini API from openai in Azure AI services.\n",
    "\n",
    "Be aware that we pay for every 1000 tokens sent (€0.00014)\tand received (€0.0006)!\n",
    "\n",
    "Feel free to adjust the below code for your hackathon project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEXuh203s7Wm",
    "outputId": "fe87f1ac-8772-47a7-f4bc-41e204f3d794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9qcw4TRasAVkDHQoDL80WmGs9GVwV\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"De Common Procurement Vocabulary (CPV) code voor het bouwen van een brug uit beton valt onder de categorieën voor bouw- en constructiewerkzaamheden. De specifieke CPV-code voor bruggenbouw is:\\n\\n- **45221100-3** - Constructiewerk voor bruggen\\n\\nDeze code is niet gespecificeerd voor het materiaal beton, maar beschrijft in brede termen het constructiewerk voor bruggen. Voor nog meer specificiteit kan het nuttig zijn om aanvullende codes te gebruiken die relevante aspecten van betonconstructies aanduiden:\\n\\n- **45223200-8** - Bouwwerkzaamheden voor constructies van beton\\n\\nHet combineren van deze codes in uw aanbestedingsdocumenten kan helpen om duidelijkheid te verschaffen over de specifieke aard van de werkzaamheden die moeten worden uitgevoerd.\\n\\nHet is altijd goed om de specifieke context van uw project te overwegen en eventueel andere relevante codes toe te passen om volledig te voldoen aan de vereisten van het project.\",\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1722329752,\n",
      "  \"model\": \"gpt-4o-2024-05-13\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_abc28019ad\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 197,\n",
      "    \"prompt_tokens\": 21,\n",
      "    \"total_tokens\": 218\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# may change in the future\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
    "api_version = \"2024-06-01\"\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    api_key=userdata.get('AZURE_OPENAI_API_KEY'),\n",
    "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
    "    azure_endpoint=userdata.get('OPENAI_ENDPOINT'),\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"hackathonllms2024-gpt4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Wat is de CPV code om een brug te bouwen uit beton?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the solution\r\n",
    "\r\n",
    "Please, make sure that your solution can support the following. It should be able to take a dataframe with the columns as provided in the example below, and return CPV-codes as predictions - one for each input row. This is necessary to run the scoring algorithm. You can get the scoring data [here](https://stllmchallenge2024.blob.core.windows.net/data/scoring_dataset.csv?sp=r&st=2024-09-08T13:38:32Z&se=2024-09-11T21:38:32Z&spr=https&sv=2022-11-02&sr=b&sig=m19SyuKrSEl1nYqaV1z00Cg9MYmSwlBfX2kSuCFd%2FHY%3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pd.read_csv(\"scoring_dataset.csv\")\n",
    "X_test = pd.DataFrame(\n",
    "    {\n",
    "        \"description\": [\"tender description 1\", \"tender description 2\", \"tender description 3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "def predict(X: pd.DataFrame) -> pd.DataFrame:\n",
    "  # Take a DataFrame with \"description\" column as input, use it to predict CPV codes\n",
    "  # and put them in a \"prediction\" column of an output dataframe!\n",
    "  return pd.DataFrame({\"prediction\": [\"12345678-0\", \"12345678-0\", \"12345678-0\"]})\n",
    "\n",
    "predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/RoyalHaskoningDHV/llm-hackathon2024@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_hackathon.scoring import score_solution\n",
    "\n",
    "score_solution(predictions)  # The first value is the F1 score, the second value is accuracy weighted by detail and importance to zwolle"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOtJjixWSnnJaxXpkrRctio",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
